## 1. Large Language Model (大语言模型)

### **LLM**

是一种人工智能模型，通常包含**数百亿（或更多）参数**的语言模型，**旨在理解和生成人类语言**。国外的有GPT-3 、GPT-4、PaLM 、Galactica 和 LLaMA 等，国内的有ChatGLM、文心一言、通义千问、讯飞星火等。

### **应用与影响：**

- **自然语言处理领域**：
  - 文本生成
  - 问答系统
  - 语言翻译

- **信息检索领域**：
  - 搜索引擎优化

- **计算机视觉领域**：
  - 图像理解和文字
  - 多媒体交互

## 2.能力与特点

### 涌现能力

模型性能随着规模增大而迅速提升，超过了随机水平，也就是我们常说的量变引起了质变。三个典型的LLM涌现能力：

1. **上下文学习**：允许语言模型通过理解上下文并生成相应输出的方式来执行任务，而无需额外的训练或参数更新。
2. **指令遵循**： `指令微调` ，LLM能够根据任务指令执行任务，而无需事先见过具体示例
3. **逐步推理**：采用 `思维链` 推理策略，利用包含中间推理步骤的提示机制来解决这些任务，从而得出最终答案。

### 基座模型支持多元应用

2021 年，Stanford 提出了 *基座模型 foundation model*，这是一种全新的 AI 技术范式。记住与海量无标注数据的训练，获得可以适用于大量下游任务的大模型

### 支持对话作为统一入口

基于语音对话的产品受欢迎，反映出互联网用户对于聊天和对话这种交互模式的偏好，ChatGPT让大语言模型真正火爆



## 3.常见的大模型

### 闭源

- **GPT 系列：**

  通过语言建模将世界知识压缩到仅解码器的 Transformer 模型中。两个关键点：

  - 训练能够准确预测下一个单词的仅解码器的 Transformer 语言模型
  - 扩展语言模型的大小。

- **Claude 系列：**

  OpenAI 离职人员创建的 Anthropic 公司开发的闭源语言大模型，通过无监督预训练、基于人类反馈的强化学习和 Constitutional AI 技术（包含监督训练和强化学习）进行训练

  - 可以更好地生成 JSON、XML、YAML、代码和 Markdown 格式的正确输出

- **PaLM 系列**:

  Google 开发, 基于 Google 提出的 Pathways 机器学习系统搭建，训练数据总量达 780B 个字符，内容涵盖网页、书籍、新闻、开源代码等多种形式的语料.

  - 最优的缩放比例（训练数据大小/模型参数量）
  - 混合了百种语言，包括了网络文档、书籍、代码、数学和对话数据

- **文心一言：**

  百度文心大模型的知识增强语言大模型，基于飞桨深度学习框架进行训练。

### 开源

- **LLaMA 系列**：

  Meta 开源的一组参数规模 从 7B 到 70B 的基础语言模型，使用了大规模的数据过滤和清洗技术

- **GLM 系列**：

  清华大学和智谱 AI 等合作研发的开源语言大模型。基于 GLM 结构开发的具有 62 亿参数量的语言大模型，支持 2048 的上下文长度

- **通义千问：**

  由阿里巴巴基于“通义”大模型研发

- **Baichuan系列：**

  百川智能开发的开源可商用的语言大模型，在权威的中文和英文 benchmark 上均取得同尺寸最好的效果，其基于Transformer 解码器架构。

  

## 4. LangChain

LangChain 框架是一个开源工具，充分利用了大型语言模型的强大能力，以便开发各种下游应用。它的目标是为各种大型语言模型应用提供通用接口，从而简化应用程序的开发流程。

### 核心插件

- LangChian 作为一个大语言模型开发框架，可以将 LLM 模型（对话模型、embedding模型等）、向量数据库、交互层 Prompt、外部知识、外部代理工具整合到一起，进而可以自由构建 LLM 应用。
- LangChain 主要由以下 6 个核心模块组成:
  - **模型输入/输出（Model I/O）**：与语言模型交互的接口
  - **数据连接（Data connection）**：与特定应用程序的数据进行交互的接口
  - **链（Chains）**：将组件组合实现端到端应用。
  - **记忆（Memory）**：用于链的多次运行之间持久化应用程序状态；
  - **代理（Agents）**：扩展模型的推理能力。用于复杂的应用的调用序列；
  - **回调（Callbacks）**：扩展模型的推理能力。用于复杂的应用的调用序列；

